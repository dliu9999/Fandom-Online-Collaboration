{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download articles from https://en.wikipedia.org/wiki/Special:Export\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find related articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related(article_name, n):\n",
    "    '''\n",
    "    Given an article name, \n",
    "    returns n most related articles\n",
    "    '''\n",
    "    return wikipedia.search(article_name, results = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTS',\n",
       " 'Dynamite (BTS song)',\n",
       " 'Be (BTS album)',\n",
       " 'Run BTS',\n",
       " 'Jimin (singer, born 1995)',\n",
       " 'V (singer)',\n",
       " 'BTS albums discography',\n",
       " 'Kim Seok-jin',\n",
       " 'List of awards and nominations received by BTS',\n",
       " 'Life Goes On (BTS song)',\n",
       " 'Map of the Soul: 7',\n",
       " 'BTS videography',\n",
       " 'BTS (disambiguation)',\n",
       " 'J-Hope',\n",
       " 'List of BTS live performances',\n",
       " 'Suga (rapper)',\n",
       " 'BTS Skytrain',\n",
       " 'Wings (BTS album)',\n",
       " 'BTS World',\n",
       " 'Jungkook',\n",
       " 'DNA (BTS song)',\n",
       " 'Fake Love (BTS song)',\n",
       " 'Serendipity (BTS song)',\n",
       " 'Idol (BTS song)',\n",
       " 'Base transceiver station',\n",
       " 'Savage Love (Laxed â€“ Siren Beat)',\n",
       " 'Love Yourself World Tour',\n",
       " 'List of most-liked tweets',\n",
       " 'Love Yourself: Answer',\n",
       " 'BTS singles discography']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pages related to BTS\n",
    "find_related(\"BTS\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting XML to LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_soup(fp):\n",
    "    '''\n",
    "    Processes xml data using beautiful soup and\n",
    "    returns list of data for each page\n",
    "    '''\n",
    "    content = []\n",
    "    with open(fp, encoding = 'utf8') as file:\n",
    "\n",
    "        content = file.readlines()\n",
    "        content = \"\".join(content)\n",
    "        soup = BeautifulSoup(content, \"xml\")\n",
    "        \n",
    "    pages = soup.findAll(\"page\")\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_to_df(pages):\n",
    "    '''\n",
    "    Converts soupified xml data for Wiki pages \n",
    "    into dataframe\n",
    "    \n",
    "    pages: list of xml data for each page\n",
    "    '''\n",
    "    data = {}\n",
    "    for page in pages:\n",
    "        title = page.title.text\n",
    "        revisions = page.findAll(\"revision\")\n",
    "\n",
    "        for revision in revisions:\n",
    "            r_id = revision.id.text \n",
    "            time = revision.timestamp.text\n",
    "            try:\n",
    "                try:\n",
    "                    username = revision.contributor.username.text\n",
    "                except: \n",
    "                    username = revision.contributor.ip.text\n",
    "            except:\n",
    "                username = 'N/A'\n",
    "            text = revision.format.next_sibling.next_sibling.text\n",
    "            if title in data:\n",
    "                data[title].append([title, r_id, time, username, text])\n",
    "            else:\n",
    "                data[title] = [[title, r_id, time, username, text]]\n",
    "    \n",
    "    dframes = []\n",
    "    for page in data:\n",
    "\n",
    "        df = pd.DataFrame(data[page], columns = ['title', 'id', 'time', 'username', 'text'])\n",
    "\n",
    "        hist = [] #history of text\n",
    "        version = [] #edit version\n",
    "        username = []\n",
    "        revert = [] #0 or 1\n",
    "        curr = 1 #to keep track of version\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            if row.text not in hist: # not a revert\n",
    "                hist.append(row.text)\n",
    "                version.append(curr)\n",
    "                username.append(row.username)\n",
    "                revert.append('0')\n",
    "                curr += 1\n",
    "            else: #is revert\n",
    "                temp = hist.index(row.text)\n",
    "                version.append(version[temp])\n",
    "                username.append(row.username)\n",
    "\n",
    "                #if self revert\n",
    "                if row.username == username[version[temp]]:\n",
    "                    revert.append('0')\n",
    "                else:\n",
    "                    revert.append('1')\n",
    "\n",
    "\n",
    "        df['version'] = version\n",
    "        df['revert'] = revert\n",
    "        dframes.append(df)\n",
    "\n",
    "    return dframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_ld(dframes, outpath):\n",
    "    '''\n",
    "    Given a list of cleaned dataframes from xml data,\n",
    "    produces light dump file into data/raw\n",
    "    '''\n",
    "    \n",
    "    light_dump = ''\n",
    "    for df in dframes:\n",
    "        title = df.title[0]\n",
    "        light_dump = light_dump + title + '\\n'\n",
    "        for idx, row in df.iterrows():\n",
    "            line = '^^^_' + row.time + ' ' + row.revert + ' ' + str(row.version) + ' ' + row.username\n",
    "            light_dump = light_dump + line + '\\n'\n",
    "    with open(outpath, 'w') as f:\n",
    "        f.write(light_dump)\n",
    "    repo = 'XML Converted to light dump at ' + outpath\n",
    "    print(repo)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_light_dump(fp, outfp):\n",
    "    '''\n",
    "    Given an input file path and output path, \n",
    "    turns the xml file into a light dump \n",
    "    and stores it at the output file path\n",
    "    '''\n",
    "    #create light dump directory first\n",
    "    if not os.path.isdir(\"../data/raw/light_dump\"):\n",
    "        os.mkdir(\"../data/raw/light_dump\")\n",
    "    \n",
    "    #convert to light dump\n",
    "    soup = xml_to_soup(fp)\n",
    "    dframes = soup_to_df(soup)\n",
    "    return df_to_ld(dframes, outfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML Converted to light dump at ../data/raw/light_dump/bts_light_dump.txt\n"
     ]
    }
   ],
   "source": [
    "fp = \"../data/raw/bts-current-revision.xml\"\n",
    "outfp = \"../data/raw/light_dump/bts_light_dump.txt\"\n",
    "xml_to_light_dump(fp, outfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store revision content in separate txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_to_df_with_content(pages):\n",
    "    '''\n",
    "    Converts soupified xml data for Wiki pages \n",
    "    into dataframe\n",
    "    \n",
    "    pages: list of xml data for each page\n",
    "    '''\n",
    "    data = {}\n",
    "    for page in pages:\n",
    "        title = page.title.text\n",
    "        revisions = page.findAll(\"revision\")\n",
    "\n",
    "        for revision in revisions:\n",
    "            r_id = revision.id.text \n",
    "            time = revision.timestamp.text\n",
    "            try:\n",
    "                try:\n",
    "                    username = revision.contributor.username.text\n",
    "                except: \n",
    "                    username = revision.contributor.ip.text\n",
    "            except:\n",
    "                username = 'N/A'\n",
    "            text = revision.format.next_sibling.next_sibling.text\n",
    "            if title in data:\n",
    "                data[title].append([title, r_id, time, username, text])\n",
    "            else:\n",
    "                data[title] = [[title, r_id, time, username, text]]\n",
    "    \n",
    "    dframes = []\n",
    "    for page in data:\n",
    "\n",
    "        df = pd.DataFrame(data[page], columns = ['title', 'id', 'time', 'username', 'text'])\n",
    "\n",
    "        hist = [] #history of text\n",
    "        version = [] #edit version\n",
    "        username = []\n",
    "        revert = [] #0 or 1\n",
    "        curr = 1 #to keep track of version\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            if row.text not in hist: # not a revert\n",
    "                hist.append(row.text)\n",
    "                version.append(curr)\n",
    "                username.append(row.username)\n",
    "                revert.append('0')\n",
    "                curr += 1\n",
    "            else: #is revert\n",
    "                temp = hist.index(row.text)\n",
    "                version.append(version[temp])\n",
    "                username.append(row.username)\n",
    "\n",
    "                #if self revert\n",
    "                if row.username == username[version[temp]]:\n",
    "                    revert.append('0')\n",
    "                else:\n",
    "                    revert.append('1')\n",
    "\n",
    "\n",
    "        df['version'] = version\n",
    "        df['revert'] = revert\n",
    "        df['text'] = text\n",
    "        dframes.append(df)\n",
    "\n",
    "    return dframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_content(dframes, outpath):\n",
    "    '''\n",
    "    Given a list of cleaned dataframes from xml data,\n",
    "    produces light dump file into data/raw\n",
    "    '''\n",
    "    \n",
    "    content = ''\n",
    "    for df in dframes:\n",
    "        title = df.title[0]\n",
    "        content = content + title + '\\n'\n",
    "        for idx, row in df.iterrows():\n",
    "            line = '^^^_' + str(row.version) + ' ' + row.username + '\\n' + row.text\n",
    "            content = content + line + '\\n'\n",
    "    with open(outpath, 'w') as f:\n",
    "        f.write(content)\n",
    "    repo = 'XML Converted to content at ' + outpath\n",
    "    print(repo)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_xml_content(fp, outfp):\n",
    "    '''\n",
    "    Given an input file path and output path, \n",
    "    stores the revision content in the xml file\n",
    "    at the output file path\n",
    "    '''\n",
    "    #create content directory first\n",
    "    if not os.path.isdir(\"../data/raw/content\"):\n",
    "        os.mkdir(\"../data/raw/content\")\n",
    "    \n",
    "    #convert to light dump\n",
    "    soup = xml_to_soup(fp)\n",
    "    dframes = soup_to_df_with_content(soup)\n",
    "    return df_to_content(dframes, outfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML Converted to content at ../data/raw/content/bts_content.txt\n"
     ]
    }
   ],
   "source": [
    "fp = \"../data/raw/bts-current-revision.xml\"\n",
    "outfp = \"../data/raw/content/bts_content.txt\"\n",
    "store_xml_content(fp, outfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try on larger kpop file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML Converted to light dump at ../data/raw/light_dump/kpop.txt\n"
     ]
    }
   ],
   "source": [
    "fp = \"../data/raw/BTS-blackpink-girlsgen-jbieber-tswift.xml\"\n",
    "outfp = \"../data/raw/light_dump/kpop.txt\"\n",
    "xml_to_light_dump(fp, outfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML Converted to content at ../data/raw/content/kpop_content.txt\n"
     ]
    }
   ],
   "source": [
    "outfp = \"../data/raw/content/kpop_content.txt\"\n",
    "store_xml_content(fp, outfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
